{"ast":null,"code":"import { wp } from '../wordpress/api'; // A. Use wpapi to pull a specific paper\n// B. Take all html from that paper and feed it to particle finder\n\nconst sampleUrl = 'https://www.thepathoftruth.com/what-the-lord-has-done-with-me/part9/p1.htm';\nconst domainUrl = 'https://www.thepathoftruth.com/';\nconst theoAuto = 'what-the-lord-has-done-with-me/';\n\nconst getChapter = n => `part${n}/`;\n\nconst getPage = n => `p${n}`;\n\nexport const theoAutoURL = (chapter, page) => domainUrl + theoAuto + getChapter(chapter) + getPage(page) + '.htm';\nexport const getPaperByUrl = (url = '') => {\n  if (!url) {\n    console.warn('cannot handle an empty url');\n    return;\n  }\n\n  console.log('searching for url :>> ', url);\n  return wp.pages() // .path(url)\n  .then(result => console.log('result :>> ', result)).catch(error => console.error(error.message)); //.map(r=>r.content)\n}; // getPaperByUrl(sampleUrl)\n\ngetPaperByUrl(theoAutoURL(9, 1)); // const result = await getPaperByUrl(sampleUrl)\n// console.log('result :>> ', result)\n// 1. Find tags around a Particle\n//  a. Verify title is 'Particle'\n//  b. Take the contents within that particle and run countWords() on it.\n// 2. Create a countWords() function that creates a weighted hashmap of individual words and their counts.","map":{"version":3,"sources":["/home/michael/Desktop/CodeProjects/TPOT/TPOT-sitescan/particle-parser/components/particle-scanner.ts"],"names":["wp","sampleUrl","domainUrl","theoAuto","getChapter","n","getPage","theoAutoURL","chapter","page","getPaperByUrl","url","console","warn","log","pages","then","result","catch","error","message"],"mappings":"AAAA,SAASA,EAAT,QAAmB,kBAAnB,C,CAEA;AACA;;AAEA,MAAMC,SAAS,GAAG,4EAAlB;AACA,MAAMC,SAAS,GAAG,iCAAlB;AACA,MAAMC,QAAQ,GAAG,iCAAjB;;AACA,MAAMC,UAAU,GAAIC,CAAD,IAAgB,OAAMA,CAAE,GAA3C;;AACA,MAAMC,OAAO,GAAID,CAAD,IAAgB,IAAGA,CAAE,EAArC;;AACA,OAAO,MAAME,WAAW,GAAG,CAACC,OAAD,EAAkBC,IAAlB,KAAmCP,SAAS,GAAGC,QAAZ,GAAuBC,UAAU,CAACI,OAAD,CAAjC,GAA6CF,OAAO,CAACG,IAAD,CAApD,GAA4D,MAAnH;AAEP,OAAO,MAAMC,aAAa,GAAG,CAACC,GAAW,GAAG,EAAf,KAAsB;AAC/C,MAAI,CAACA,GAAL,EAAU;AACNC,IAAAA,OAAO,CAACC,IAAR,CAAa,4BAAb;AACA;AACH;;AACDD,EAAAA,OAAO,CAACE,GAAR,CAAY,wBAAZ,EAAsCH,GAAtC;AACA,SAAOX,EAAE,CAACe,KAAH,GACH;AADG,GAEFC,IAFE,CAEGC,MAAM,IAAIL,OAAO,CAACE,GAAR,CAAY,aAAZ,EAA2BG,MAA3B,CAFb,EAGFC,KAHE,CAGIC,KAAK,IAAGP,OAAO,CAACO,KAAR,CAAcA,KAAK,CAACC,OAApB,CAHZ,CAAP,CAN+C,CAW3C;AAEP,CAbM,C,CAgBP;;AACAV,aAAa,CAACH,WAAW,CAAC,CAAD,EAAG,CAAH,CAAZ,CAAb,C,CAEA;AACA;AAEA;AACA;AACA;AACA","sourcesContent":["import { wp } from '../wordpress/api';\n\n// A. Use wpapi to pull a specific paper\n// B. Take all html from that paper and feed it to particle finder\n\nconst sampleUrl = 'https://www.thepathoftruth.com/what-the-lord-has-done-with-me/part9/p1.htm'\nconst domainUrl = 'https://www.thepathoftruth.com/'\nconst theoAuto = 'what-the-lord-has-done-with-me/'\nconst getChapter = (n: number) => `part${n}/`;\nconst getPage = (n: number) => `p${n}`;\nexport const theoAutoURL = (chapter: number, page: number) => domainUrl + theoAuto + getChapter(chapter) + getPage(page)+ '.htm';\n\nexport const getPaperByUrl = (url: string = '') => {\n    if (!url) {\n        console.warn('cannot handle an empty url');\n        return\n    }\n    console.log('searching for url :>> ', url);\n    return wp.pages()\n        // .path(url)\n        .then(result => console.log('result :>> ', result))\n        .catch(error=> console.error(error.message))\n\n        //.map(r=>r.content)\n        \n}\n\n\n// getPaperByUrl(sampleUrl)\ngetPaperByUrl(theoAutoURL(9,1))\n\n// const result = await getPaperByUrl(sampleUrl)\n// console.log('result :>> ', result)\n\n// 1. Find tags around a Particle\n//  a. Verify title is 'Particle'\n//  b. Take the contents within that particle and run countWords() on it.\n// 2. Create a countWords() function that creates a weighted hashmap of individual words and their counts.\n\n"]},"metadata":{},"sourceType":"module"}