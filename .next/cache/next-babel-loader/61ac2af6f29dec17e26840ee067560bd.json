{"ast":null,"code":"import { wp } from '../wordpress/api'; // A. Use wpapi to pull a specific paper\n// B. Take all html from that paper and feed it to particle finder\n\nvar sampleUrl = 'https://www.thepathoftruth.com/what-the-lord-has-done-with-me/part9/p1.htm';\nexport var getPaperByUrl = function getPaperByUrl() {\n  var url = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  return wp.pages(); // .then(result => console.log('result :>> ', result))\n};\nvar result = await getPaperByUrl(sampleUrl);\nconsole.log('result :>> ', result); // 1. Find tags around a Particle\n//  a. Verify title is 'Particle'\n//  b. Take the contents within that particle and run countWords() on it.\n// 2. Create a countWords() function that creates a weighted hashmap of individual words and their counts.","map":{"version":3,"sources":["/home/michael/Desktop/CodeProjects/TPOT/TPOT-sitescan/particle-parser/components/particle-scanner.js"],"names":["wp","sampleUrl","getPaperByUrl","url","pages","result","console","log"],"mappings":"AAAA,SAASA,EAAT,QAAmB,kBAAnB,C,CAEA;AACA;;AAEA,IAAMC,SAAS,GAAG,4EAAlB;AACA,OAAO,IAAMC,aAAa,GAAG,SAAhBA,aAAgB,GAAc;AAAA,MAAbC,GAAa,uEAAP,EAAO;AACvC,SAAOH,EAAE,CAACI,KAAH,EAAP,CADuC,CAEnC;AACP,CAHM;AAKP,IAAMC,MAAM,GAAG,MAAMH,aAAa,CAACD,SAAD,CAAlC;AACAK,OAAO,CAACC,GAAR,CAAY,aAAZ,EAA2BF,MAA3B,E,CAEA;AACA;AACA;AACA","sourcesContent":["import { wp } from '../wordpress/api';\n\n// A. Use wpapi to pull a specific paper\n// B. Take all html from that paper and feed it to particle finder\n\nconst sampleUrl = 'https://www.thepathoftruth.com/what-the-lord-has-done-with-me/part9/p1.htm'\nexport const getPaperByUrl = (url = '') => {\n    return wp.pages()\n        // .then(result => console.log('result :>> ', result))\n}\n\nconst result = await getPaperByUrl(sampleUrl)\nconsole.log('result :>> ', result)\n\n// 1. Find tags around a Particle\n//  a. Verify title is 'Particle'\n//  b. Take the contents within that particle and run countWords() on it.\n// 2. Create a countWords() function that creates a weighted hashmap of individual words and their counts.\n\n"]},"metadata":{},"sourceType":"module"}