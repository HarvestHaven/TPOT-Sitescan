{"ast":null,"code":"import { wp } from '../wordpress/api'; // A. Use wpapi to pull a specific paper\n// B. Take all html from that paper and feed it to particle finder\n\nvar sampleUrl = 'https://www.thepathoftruth.com/what-the-lord-has-done-with-me/part9/p1.htm';\nexport var getPaperByUrl = function getPaperByUrl() {\n  var url = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n  return wp.pages().then(function (result) {\n    return console.log('result :>> ', result);\n  });\n};\ngetPaperByUrl(sampleUrl); // const result = await getPaperByUrl(sampleUrl)\n// console.log('result :>> ', result)\n// 1. Find tags around a Particle\n//  a. Verify title is 'Particle'\n//  b. Take the contents within that particle and run countWords() on it.\n// 2. Create a countWords() function that creates a weighted hashmap of individual words and their counts.","map":{"version":3,"sources":["/home/michael/Desktop/CodeProjects/TPOT/TPOT-sitescan/particle-parser/components/particle-scanner.ts"],"names":["wp","sampleUrl","getPaperByUrl","url","pages","then","result","console","log"],"mappings":"AAAA,SAASA,EAAT,QAAmB,kBAAnB,C,CAEA;AACA;;AAEA,IAAMC,SAAS,GAAG,4EAAlB;AACA,OAAO,IAAMC,aAAa,GAAG,SAAhBA,aAAgB,GAAc;AAAA,MAAbC,GAAa,uEAAP,EAAO;AACvC,SAAOH,EAAE,CAACI,KAAH,GACFC,IADE,CACG,UAAAC,MAAM;AAAA,WAAIC,OAAO,CAACC,GAAR,CAAY,aAAZ,EAA2BF,MAA3B,CAAJ;AAAA,GADT,CAAP;AAEH,CAHM;AAKPJ,aAAa,CAACD,SAAD,CAAb,C,CAEA;AACA;AAEA;AACA;AACA;AACA","sourcesContent":["import { wp } from '../wordpress/api';\n\n// A. Use wpapi to pull a specific paper\n// B. Take all html from that paper and feed it to particle finder\n\nconst sampleUrl = 'https://www.thepathoftruth.com/what-the-lord-has-done-with-me/part9/p1.htm'\nexport const getPaperByUrl = (url = '') => {\n    return wp.pages()\n        .then(result => console.log('result :>> ', result))\n}\n\ngetPaperByUrl(sampleUrl)\n\n// const result = await getPaperByUrl(sampleUrl)\n// console.log('result :>> ', result)\n\n// 1. Find tags around a Particle\n//  a. Verify title is 'Particle'\n//  b. Take the contents within that particle and run countWords() on it.\n// 2. Create a countWords() function that creates a weighted hashmap of individual words and their counts.\n\n"]},"metadata":{},"sourceType":"module"}