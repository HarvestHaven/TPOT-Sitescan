{"ast":null,"code":"import { wp } from '../wordpress/api'; // A. Use wpapi to pull a specific paper\n// B. Take all html from that paper and feed it to particle finder\n\nvar sampleUrl = 'https://www.thepathoftruth.com/what-the-lord-has-done-with-me/part9/p1.htm';\nvar domainUrl = 'https://www.thepathoftruth.com/';\nvar theoAuto = 'what-the-lord-has-done-with-me/';\n\nvar part = function part(n) {\n  return \"part\".concat(n, \"/\");\n};\n\nvar page = function page(n) {\n  return \"p\".concat(n);\n};\n\nexport var theoAutoURL = function theoAutoURL(chapter, page) {\n  return domainUrl + theoAuto + part(chapter) + '.htm';\n};\nexport var getPaperByUrl = function getPaperByUrl() {\n  var url = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : '';\n\n  if (!url) {\n    console.warn('cannot handle an empty url');\n    return;\n  }\n\n  console.log('searching for url :>> ', url);\n  return wp.pages() // .path(url)\n  .then(function (result) {\n    return console.log('result :>> ', result);\n  });\n}; // getPaperByUrl(sampleUrl)\n\ngetPaperByUrl(theoAutoURL(9, 1)); // const result = await getPaperByUrl(sampleUrl)\n// console.log('result :>> ', result)\n// 1. Find tags around a Particle\n//  a. Verify title is 'Particle'\n//  b. Take the contents within that particle and run countWords() on it.\n// 2. Create a countWords() function that creates a weighted hashmap of individual words and their counts.","map":{"version":3,"sources":["/home/michael/Desktop/CodeProjects/TPOT/TPOT-sitescan/particle-parser/components/particle-scanner.ts"],"names":["wp","sampleUrl","domainUrl","theoAuto","part","n","page","theoAutoURL","chapter","getPaperByUrl","url","console","warn","log","pages","then","result"],"mappings":"AAAA,SAASA,EAAT,QAAmB,kBAAnB,C,CAEA;AACA;;AAEA,IAAMC,SAAS,GAAG,4EAAlB;AACA,IAAMC,SAAS,GAAG,iCAAlB;AACA,IAAMC,QAAQ,GAAG,iCAAjB;;AACA,IAAMC,IAAI,GAAG,SAAPA,IAAO,CAACC,CAAD;AAAA,uBAAsBA,CAAtB;AAAA,CAAb;;AACA,IAAMC,IAAI,GAAG,SAAPA,IAAO,CAACD,CAAD;AAAA,oBAAmBA,CAAnB;AAAA,CAAb;;AACA,OAAO,IAAME,WAAW,GAAG,SAAdA,WAAc,CAACC,OAAD,EAAkBF,IAAlB;AAAA,SAAmCJ,SAAS,GAAGC,QAAZ,GAAuBC,IAAI,CAACI,OAAD,CAA3B,GAAuC,MAA1E;AAAA,CAApB;AAEP,OAAO,IAAMC,aAAa,GAAG,SAAhBA,aAAgB,GAAsB;AAAA,MAArBC,GAAqB,uEAAP,EAAO;;AAC/C,MAAI,CAACA,GAAL,EAAU;AACNC,IAAAA,OAAO,CAACC,IAAR,CAAa,4BAAb;AACA;AACH;;AACDD,EAAAA,OAAO,CAACE,GAAR,CAAY,wBAAZ,EAAsCH,GAAtC;AACA,SAAOV,EAAE,CAACc,KAAH,GACH;AADG,GAEFC,IAFE,CAEG,UAAAC,MAAM;AAAA,WAAIL,OAAO,CAACE,GAAR,CAAY,aAAZ,EAA2BG,MAA3B,CAAJ;AAAA,GAFT,CAAP;AAGH,CATM,C,CAYP;;AACAP,aAAa,CAACF,WAAW,CAAC,CAAD,EAAG,CAAH,CAAZ,CAAb,C,CAEA;AACA;AAEA;AACA;AACA;AACA","sourcesContent":["import { wp } from '../wordpress/api';\n\n// A. Use wpapi to pull a specific paper\n// B. Take all html from that paper and feed it to particle finder\n\nconst sampleUrl = 'https://www.thepathoftruth.com/what-the-lord-has-done-with-me/part9/p1.htm'\nconst domainUrl = 'https://www.thepathoftruth.com/'\nconst theoAuto = 'what-the-lord-has-done-with-me/'\nconst part = (n: number) => `part${n}/`;\nconst page = (n: number) => `p${n}`;\nexport const theoAutoURL = (chapter: number, page: number) => domainUrl + theoAuto + part(chapter) + '.htm';\n\nexport const getPaperByUrl = (url: string = '') => {\n    if (!url) {\n        console.warn('cannot handle an empty url');\n        return\n    }\n    console.log('searching for url :>> ', url);\n    return wp.pages()\n        // .path(url)\n        .then(result => console.log('result :>> ', result))\n}\n\n\n// getPaperByUrl(sampleUrl)\ngetPaperByUrl(theoAutoURL(9,1))\n\n// const result = await getPaperByUrl(sampleUrl)\n// console.log('result :>> ', result)\n\n// 1. Find tags around a Particle\n//  a. Verify title is 'Particle'\n//  b. Take the contents within that particle and run countWords() on it.\n// 2. Create a countWords() function that creates a weighted hashmap of individual words and their counts.\n\n"]},"metadata":{},"sourceType":"module"}